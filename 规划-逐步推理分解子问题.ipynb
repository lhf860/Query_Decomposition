{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fffa4787-5525-401e-a429-2db43dbd2476",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "这里主要参考了KAG的内容对RAG和KG的处理流程进行关键部分的解读来实现的。\n",
    "https://github.com/OpenSPG/KAG/tree/master/kag/solver/prompt/default\n",
    "https://github.com/OpenSPG/KAG/blob/master/kag/solver/prompt/default/logic_form_plan.py\n",
    "\n",
    "实现的要点：\n",
    "1、COT （思维链）-- 思考过程， 这里主要是根据已有的query和已经获取答案的sub query问答对，思考下一个生成的问题。\n",
    "2、Planning (任务规划) -- 规划任务，这里是根据原始的query规划所有的步骤，一步一步地来实现下一个问题的生成，一步一步规划内容。\n",
    "3、Resoning + Action(推理 + 动作)---推理答案 （下一个思考的问题） + continuing 或者 finished\n",
    "\n",
    "4、Few shot example learning --> Proompt: 在Prompt中添加了响应格式的示例， 这里是少样本学习。\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "这里的思想（通过规划plan来实现下一步的思考问题--【通过当前原始问题、已经生成的子问题+答案对（或者query与上下文文档对）、推理思考过程】）\n",
    "这里有点类似于：plan-guided reasoning rag.\n",
    "\n",
    "同时逐步获取其中思路的方法有点类似于Auto-RAG的做法：\n",
    "https://mp.weixin.qq.com/s/I_-NDGzd7d8l4zjRfCsvDQ。\n",
    "https://mp.weixin.qq.com/s/5WvlT1kl0hPBKPxhXX_qKA\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07d3f88e-045e-4296-8d06-f2ca5181e50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "openai_api_key = \"EMPTY\"\n",
    "openai_api_base = \"http://localhost:8000/v1\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42fa0c3b-1d2a-428b-b2b0-2f37fadd2335",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "template_zh = (\n",
    "        \"你是一个智能助手，擅长通过复杂的、多跳的推理帮助用户在多文档中获取信息。请理解当前已知信息与目标问题之间的信息差。\"\n",
    "        \"你的任务是直接生成一个用于下一步检索的思考问题。\"\n",
    "        \"不要一次性生成所有思考过程！\\n[已知信息]： $memory\\n[目标问题]：$instruction\\n[你的思考]：\"\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46d96d8b-752f-4834-9011-a8c041dfb550",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def query_decomposition_stepbystep(query, sloved):\n",
    "\n",
    "    system_prompt =  \"\"\"你是一个用户查询拆分的专家，擅长针对KBQA和搜索领域的查询进行分解,擅长通过复杂的多跳的推理帮助用户分解问题。\n",
    "    你的任务是直接生成一个用于下一步检索的思考问题。\n",
    "    思考问题不要借助外部知识推理，仅根据问题进行思考。\n",
    "    生成的思考问题独立明确，可直接回答或检索。\n",
    "    直接生成要思考的问题，不要其它问题的结尾词。\n",
    "    不要一次性生成所有的思考过程。\n",
    "\n",
    "    原始问题：\n",
    "    {query}\n",
    "    已经思考过的问题和答案：\n",
    "    {sloved_query}\n",
    "    下一步思考的问题：\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"您是一个有益的人工智能助手。\"},\n",
    "        {\"role\": \"user\", \"content\":  system_prompt.format(**{\"query\": query, \"sloved_query\": sloved})},\n",
    "    ]\n",
    "    chat_response = client.chat.completions.create(model=\"Qwen2.5-7B-Instruct\",messages=messages, \n",
    "                                                   temperature=0.001,\n",
    "                                                   # top_p=0.8,\n",
    "                                                   max_tokens=1024,\n",
    "                                                   extra_body={\n",
    "                                                               \"repetition_penalty\": 1.05,\n",
    "                                                       # \"guide_json\": QueryDecomposition.model_json_schema(),\n",
    "                                                       # \"guided_decoding_backend\": \"outlines\"\n",
    "                                                   }\n",
    "                                                  )\n",
    "\n",
    "    \n",
    "    \n",
    "    return chat_response.choices[0].message.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c4f4426-d6dd-4859-82b0-37c968a7224c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def judge_finish_answer(query, sloved_sub_query):\n",
    "\n",
    "    prompt = \"\"\" 跟定一个原始的用户问题和若干个已经拆分后的子问题及答案，判断是否能够回答原始的用户问题。\n",
    "    如果能回答原始问题，则输出finished和原始问题的答案answer。\n",
    "    如果不能回答原始，则输出continuing, 原始问题的答案answer为空。\n",
    "    不要输出额外的内容。\n",
    "    \n",
    "    输出结果为json，格式样例如下：\n",
    "    {{\"judge\": \"finished\", \"answer\": \"原始问题的答案\"}}\n",
    "    {{\"judge\": \"continuing\", \"answer\": \"\"}}\n",
    "    \n",
    "    原始问题：\n",
    "    {query}\n",
    "\n",
    "    已有的问题答案对：\n",
    "    {sloved_sub_query}\n",
    "    \"\"\"\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"您是一个有益的人工智能助手。\"},\n",
    "        {\"role\": \"user\", \"content\":  prompt.format(**{\"query\": query, \"sloved_sub_query\": sloved_sub_query})},\n",
    "    ]\n",
    "    chat_response = client.chat.completions.create(model=\"Qwen2.5-7B-Instruct\",messages=messages, \n",
    "                                                   temperature=0.001,\n",
    "                                                   # top_p=0.8,\n",
    "                                                   max_tokens=1024,\n",
    "                                                   extra_body={\n",
    "                                                               \"repetition_penalty\": 1.05,\n",
    "                                                       # \"guide_json\": QueryDecomposition.model_json_schema(),\n",
    "                                                       # \"guided_decoding_backend\": \"outlines\"\n",
    "                                                   }\n",
    "                                                  )\n",
    "    response = chat_response.choices[0].message.content\n",
    "    response = response.replace(\"json\", \"\").replace(\"```\", \"\")\n",
    "    \n",
    "    return response\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50e1c35f-695c-4133-a992-c8073c3f7f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"judge\": \"continuing\", \"answer\": \"\"}\n"
     ]
    }
   ],
   "source": [
    "query = \"姚明和奥尼尔谁的身高高？\"\n",
    "sloved_sub_query = \"问题：姚明的身高是多少？ 答案：2.42m\"\n",
    "response = judge_finish_answer(query, sloved_sub_query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "541b4836-f462-4b5f-9a12-b4f495b97aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "姚明的身高是多少？\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "query = \"姚明和奥尼尔谁的身高高？\"\n",
    "sloved = \"\"\n",
    "response = query_decomposition_stepbystep(query, sloved)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0d3172c-0f42-4b32-baa0-2671f284f0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_step_plan(query):\n",
    "\n",
    "    sloved_answer = \"\"\n",
    "    continuing = True\n",
    "    sub_query_index = 1\n",
    "    \n",
    "    while continuing:\n",
    "        sub_query = query_decomposition_stepbystep(query, sloved_answer)\n",
    "        response = input(f\"{sub_query_index}. {sub_query}:\")\n",
    "        sloved_answer += f\"思考问题：{sub_query}, 答案：{response}\" + \"\\n\"\n",
    "        judge_response = judge_finish_answer(query, sloved_answer)\n",
    "        judge = json.loads(judge_response)[\"judge\"]\n",
    "        if judge == \"finished\":\n",
    "            sub_query_index += 1\n",
    "            print(str(sub_query_index) + \".\", \"最终答案：\", json.loads(judge_response)[\"answer\"])\n",
    "            continuing = False\n",
    "        \n",
    "        else:\n",
    "            # print(\"子问题的解答过程：\", sloved_answer)\n",
    "            sub_query_index += 1\n",
    "            \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c84fa060-088d-414f-ad96-66498047c7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "1. 最后一届男子板球世界杯决赛的举办地在哪里？: 上海\n",
      "2. 倒数第二屆男子板球世界杯决赛的举办地在哪里？: 北京\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. 最终答案： 最后两届男子板球世界杯决赛的举办地分别在北京和上海。\n"
     ]
    }
   ],
   "source": [
    "query = \"姚明和奥尼尔谁的身高高？\"\n",
    "query = \"张三的父亲的母亲多大了\"\n",
    "query = \"耗电量最大的设备是什么时候购买的\"\n",
    "query = \"最后两届男子板球世界杯决赛的举办地之间的距离是多少\"\n",
    "query = \"最后两届男子板球世界杯决赛的举办地分别在哪里？\"\n",
    "query_step_plan(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3debb41a-f4af-4d1b-82b2-faee16cff8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "torch2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
